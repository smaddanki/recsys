{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create example tensors of different types\n",
    "float_tensor = torch.tensor([1.0, 2.0, 3.0])\n",
    "int_tensor = torch.tensor([1, 2, 3])\n",
    "bool_tensor = torch.tensor([True, False, True])\n",
    "complex_tensor = torch.complex(real=torch.rand(3), imag=torch.rand(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ===== Basic Type Checking ====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dtype of tensor\n",
    "dtype = float_tensor.dtype  # returns torch.float32\n",
    "\n",
    "# Check specific types\n",
    "is_float = float_tensor.dtype == torch.float32\n",
    "is_int = int_tensor.dtype == torch.int64\n",
    "is_bool = bool_tensor.dtype == torch.bool\n",
    "\n",
    "# Built-in type checking methods\n",
    "is_floating = float_tensor.is_floating_point()  # True for float32, float64, float16, bfloat16\n",
    "is_complex = complex_tensor.is_complex()        # True for complex64, complex128\n",
    "is_signed = int_tensor.is_signed()              # True for signed integer types\n",
    "is_inference = float_tensor.is_inference()      # True for inference-optimized dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===== Detailed Type Checking ====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tensor_type(tensor):\n",
    "    \"\"\"Comprehensive type checking for a PyTorch tensor\"\"\"\n",
    "    type_info = {\n",
    "        # Basic type information\n",
    "        'dtype': tensor.dtype,\n",
    "        'type': type(tensor),\n",
    "        \n",
    "        # Numeric type checks\n",
    "        'is_floating_point': tensor.is_floating_point(),\n",
    "        'is_complex': tensor.is_complex(),\n",
    "        'is_signed': tensor.is_signed(),\n",
    "        \n",
    "        # Memory format checks\n",
    "        'is_contiguous': tensor.is_contiguous(),\n",
    "        'is_pinned': tensor.is_pinned() if torch.cuda.is_available() else False,\n",
    "        \n",
    "        # Device checks\n",
    "        'is_cuda': tensor.is_cuda,\n",
    "        'is_cpu': tensor.device.type == 'cpu',\n",
    "        \n",
    "        # Other properties\n",
    "        'requires_grad': tensor.requires_grad,\n",
    "        'is_leaf': tensor.is_leaf,\n",
    "        'is_sparse': tensor.is_sparse,\n",
    "        'is_quantized': tensor.is_quantized,\n",
    "        'is_nested': tensor.is_nested if hasattr(tensor, 'is_nested') else False,\n",
    "    }\n",
    "    return type_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===== Size and Shape Checking ====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tensor_shape(tensor):\n",
    "    \"\"\"Check tensor shape and dimension properties\"\"\"\n",
    "    shape_info = {\n",
    "        'shape': tensor.shape,\n",
    "        'ndim': tensor.ndim,\n",
    "        'size': tensor.size(),\n",
    "        'numel': tensor.numel(),  # total number of elements\n",
    "        'is_scalar': tensor.ndim == 0,\n",
    "        'is_vector': tensor.ndim == 1,\n",
    "        'is_matrix': tensor.ndim == 2\n",
    "    }\n",
    "    return shape_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===== Type Compatibility Checking ====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_type_compatibility(tensor1, tensor2):\n",
    "    \"\"\"Check if two tensors have compatible types for operations\"\"\"\n",
    "    compatibility = {\n",
    "        'same_dtype': tensor1.dtype == tensor2.dtype,\n",
    "        'same_device': tensor1.device == tensor2.device,\n",
    "        'both_floating': tensor1.is_floating_point() and tensor2.is_floating_point(),\n",
    "        'both_complex': tensor1.is_complex() and tensor2.is_complex(),\n",
    "        'can_add': torch.can_cast(tensor1.dtype, tensor2.dtype)\n",
    "    }\n",
    "    return compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float32 Tensor Type Info:\n",
      "{'dtype': torch.float32, 'type': <class 'torch.Tensor'>, 'is_floating_point': True, 'is_complex': False, 'is_signed': True, 'is_contiguous': True, 'is_pinned': False, 'is_cuda': False, 'is_cpu': True, 'requires_grad': False, 'is_leaf': True, 'is_sparse': False, 'is_quantized': False, 'is_nested': False}\n",
      "\n",
      "Shape Info:\n",
      "{'shape': torch.Size([2]), 'ndim': 1, 'size': torch.Size([2]), 'numel': 2, 'is_scalar': False, 'is_vector': True, 'is_matrix': False}\n",
      "\n",
      "Type Compatibility:\n",
      "{'same_dtype': False, 'same_device': True, 'both_floating': True, 'both_complex': False, 'can_add': True}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create tensors of different types\n",
    "float32_tensor = torch.tensor([1.0, 2.0], dtype=torch.float32)\n",
    "float64_tensor = torch.tensor([1.0, 2.0], dtype=torch.float64)\n",
    "int32_tensor = torch.tensor([1, 2], dtype=torch.int32)\n",
    "\n",
    "# Check type information\n",
    "print(\"Float32 Tensor Type Info:\")\n",
    "print(check_tensor_type(float32_tensor))\n",
    "\n",
    "# Check shape information\n",
    "print(\"\\nShape Info:\")\n",
    "print(check_tensor_shape(float32_tensor))\n",
    "\n",
    "# Check compatibility\n",
    "print(\"\\nType Compatibility:\")\n",
    "print(check_type_compatibility(float32_tensor, float64_tensor))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ===== Type Safety Checks ====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_operation(tensor1, tensor2, operation='add'):\n",
    "    \"\"\"Safely perform operation after type checking\"\"\"\n",
    "    if not tensor1.is_floating_point() and not tensor2.is_floating_point():\n",
    "        raise TypeError(\"At least one tensor should be floating point\")\n",
    "    \n",
    "    if tensor1.device != tensor2.device:\n",
    "        raise ValueError(\"Tensors must be on the same device\")\n",
    "    \n",
    "    if operation == 'add':\n",
    "        return torch.add(tensor1, tensor2)\n",
    "    elif operation == 'multiply':\n",
    "        return torch.mul(tensor1, tensor2)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported operation: {operation}\")\n",
    "\n",
    "# ===== Memory Format Checking =====\n",
    "def check_memory_format(tensor):\n",
    "    \"\"\"Check tensor's memory format\"\"\"\n",
    "    format_info = {\n",
    "        'is_contiguous': tensor.is_contiguous(),\n",
    "        'is_contiguous_channels_last': tensor.is_contiguous(memory_format=torch.channels_last),\n",
    "        'is_contiguous_channels_last_3d': tensor.is_contiguous(memory_format=torch.channels_last_3d),\n",
    "        'stride': tensor.stride(),\n",
    "    }\n",
    "    return format_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
